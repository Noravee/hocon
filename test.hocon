llm_config {
  model_name = "gpt-4.5-preview-2025-02-27"
  temperature = 0.5
}
tools = [
  {
    name = "a"
    class = ""
    function {}
    instructions = """When you receive an inquiry, you will:

    1. Call your tools to determine which down-chain agents in your tools are
       responsible for all or part of it.
    2. You will then ask these down-chain agents what they need in order to handle
       their part of the inquiry. Once the requirements are gathered, you will,
    3. Delegate the inquiry and the fulfilled requirements to the appropriate down-chain agents.
    4. Once all down-chain agents respond, you will compile their responses and return the final response.

You may, in turn, be called by other agents in the system and have to act as a down-chain to them."""
    command = ""
    tools = []
    llm_config {
      model_name = "gpt-4.5-preview-2025-02-27"
      temperature = 0.5
    }
  }
  {
    name = "b"
    class = null
    function {}
    instructions = ""
    command = "Explain if you can respond to all or parts of the inquiry and what you need in order to respond, if anything."
    tools = []
    llm_config {
      model_name = "gpt-4.5-preview-2025-02-27"
      temperature = 0.5
    }
  }
]